package com.exasol.adapter.dialects.exasol;

import com.exasol.adapter.AdapterProperties;
import com.exasol.adapter.dialects.IdentifierConverter;
import com.exasol.adapter.jdbc.BaseTableMetadataReader;
import com.exasol.adapter.jdbc.ColumnMetadataReader;
import com.exasol.adapter.jdbc.Wildcards;
import com.exasol.adapter.metadata.ColumnMetadata;
import com.exasol.adapter.metadata.TableMetadata;
import com.exasol.adapter.properties.TableCountLimit;
import com.exasol.errorreporting.ExaError;
import com.exasol.jdbc.EXAResultSet;

import java.sql.Connection;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.*;
import java.util.logging.Logger;

import static com.exasol.adapter.jdbc.RemoteMetadataReaderConstants.ANY_COLUMN;
import static com.exasol.adapter.jdbc.RemoteMetadataReaderConstants.ANY_TABLE;

/**
 * Specific table reader for Exasol, reading column metadata in bulk.
 *
 * TODO - design decision; while the default JDBC implementation is especially bad for Exasol, the optimized approach
 * should be valid for all JDBC-compliant databases / drivers...
 */
public class ExasolTableMetadataReader extends BaseTableMetadataReader {
    private static final Logger LOGGER = Logger.getLogger(ExasolTableMetadataReader.class.getName());

    // return status for seekSchema() and seekTable()
    private enum SeekResult {
        FOUND, NOT_FOUND, END_OF_RESULT_SET
    }

    /**
     * Create a new instance of a {@link ExasolTableMetadataReader}.
     *
     * @param connection           JDBC connection to remote data source
     * @param columnMetadataReader reader to be used to map the tables columns
     * @param properties           user-defined adapter properties
     * @param identifierConverter  converter between source and Exasol identifiers
     */
    public ExasolTableMetadataReader(Connection connection, ExasolColumnMetadataReader columnMetadataReader,
            AdapterProperties properties, IdentifierConverter identifierConverter) {
        super(connection, columnMetadataReader, properties, identifierConverter);
    }

    // arbitrary border to switch between default iterative and "all in" column scan
    static final double FILTER_RATIO_THRESHOLD = 0.1;

    private ExasolColumnMetadataReader getColumnReader() {
        // type asserted by constructor
        return (ExasolColumnMetadataReader) this.columnMetadataReader;
    }

    private String readSchemaName(final ResultSet metadata) throws SQLException {
        return metadata.getString("TABLE_SCHEM");
    }

    @Override
    public List<TableMetadata> mapTables(ResultSet remoteTables, List<String> filteredTables) throws SQLException {
        // TODO: the decision tree may be over-engineered; up for discussion

        // must not iterate the ResultSet yet, because super implementation will immediately call next()
        long numberOfTables = ((EXAResultSet) remoteTables).getNumberOfRows();
        long filteredTableCount = filteredTables.size();

        if (numberOfTables == 0) {
            LOGGER.warning(() -> ExaError.messageBuilder("W-VSEXA-9")
                    .message("Table scan did not find any tables. This can mean that either" //
                            + " a) the source does not contain tables (yet)," + " b) the table type is not supported" //
                            + " c) the user does not have access permissions.")
                    .mitigation("Please check that the source actually contains tables. " //
                            + " Also check the spelling and exact case of any catalog or schema name you provided.")
                    .toString());
            return Collections.emptyList();
        }

        if (filteredTableCount > 0 && filteredTableCount < FILTER_RATIO_THRESHOLD * numberOfTables) {
            // strong filter, use default jdbc implementation
            return super.mapTables(remoteTables, filteredTables);
        }

        return mapTablesBatch(remoteTables, filteredTables);
    }

    /**
     * Optimized version of BaseTableMetadataReader::mapTables, which uses a single call to DatabaseMetadata::getColumns
     * instead of one call per table. Massive speedup for Exasol clusters.
     *
     * @param remoteTables   ResultSet generated by DatabaseMetadata::getTables(), sorted by TABLE_TYPE, TABLE_CAT,
     *                       TABLE_SCHEM, TABLE_NAME
     * @param filteredTables Optional list of table names to accept; case-sensitive, no wildcard support
     * @return Metadata for mapped tables; may be empty.
     * @throws SQLException When any ResultSet operation fails
     */
    private List<TableMetadata> mapTablesBatch(ResultSet remoteTables, List<String> filteredTables)
            throws SQLException {
        // step 1: go through table ResultSet once, put them into a sorted map (sort by TABLE_TYPE is bad)
        SortedMap<String, SortedMap<String, String>> sortedSchemas = sortTablesResult(remoteTables, filteredTables);
        if (sortedSchemas.isEmpty()) {
            // by check W-VSEXA-5, the unfiltered table list was not empty.
            LOGGER.warning(() -> ExaError.messageBuilder("W-VSEXA-10")
                    .message("Table scan did not find any of the listed tables. This can mean that either" //
                            + " a) the table type is not supported" //
                            + " b) the names do not match up" //
                            + " c) the user does not have access permissions.")
                    .mitigation(
                            "Please check the spelling and exact case of any catalog or schema name you provided. Also check that the remote user does have access to the tables.")
                    .toString());

            return Collections.emptyList();
        }

        // TODO - maybe exchange the SchemaNameFilter with the schema name from the SortedMap if there is only one
        //        entry. However, non-qualified Virtual Schemas are broken anyway...

        ResultSet columnList = this.connection.getMetaData().getColumns(
                getCatalogNameFilter(),
                Wildcards.escape(getSchemaNameFilter()), // no null-check as the parameter is mandatory
                ANY_TABLE, ANY_COLUMN);
        if (!columnList.next()) {
            LOGGER.warning(() -> ExaError.messageBuilder("W-VSEXA-7").message(
                    "Column scan did not find any columns for schema {{schema_name}}. This should only happen when the schema contains only views that have not been initialized yet.")
                    .parameter("schema_name", getSchemaNameFilter())
                    .mitigation("Please check the remote system.").toString());
            return Collections.emptyList();
        }

        // step 2: now we can "merge sort" table and column list based on sort key prefix (schema name, table name)
        return mapSortedSchemas(sortedSchemas, columnList);
    }

    private List<TableMetadata> mapSortedSchemas(SortedMap<String, SortedMap<String, String>> sortedSchemas,
                                                 ResultSet columnList) throws SQLException {

        List<TableMetadata> mappedTables = new ArrayList<>();

        for (Map.Entry<String, SortedMap<String, String>> schemaEntry : sortedSchemas.entrySet()) {
            mappedTables.addAll(mapOneSchema(columnList, schemaEntry.getKey(), schemaEntry.getValue()));
        }
        if (mappedTables.isEmpty()) {
            LOGGER.warning(() -> ExaError.messageBuilder("W-VSEXA-8").message(
                    "Column mapping filtered out all available table columns. This indicates that the remote system only contains incompatible data types.")
                    .mitigation("Please check the remote system.").toString());
        }
        return mappedTables;
    }

    // map all tables in the schema given by schemaEntry
    private List<TableMetadata> mapOneSchema(ResultSet columnList, String schemaName, SortedMap<String, String> tableMap) throws SQLException {
        switch (seekSchema(columnList, schemaName)) {
        case END_OF_RESULT_SET:
            // could tell the higher-up caller, but looping is not expensive from here on out
        case NOT_FOUND:
            for (String tableName : tableMap.keySet() ) {
                logSkippingTableWithEmptyColumns(tableName);
            }
            return Collections.emptyList();
        case FOUND:
            // all good
            break;
        }

        List<TableMetadata> mappedTables = new ArrayList<>();
        TableCountLimit tableCountLimit = TableCountLimit.from(this.properties);

        for (Map.Entry<String, String> tableEntry : tableMap.entrySet()) {
            mappedTables.addAll(mapOneTable(columnList, tableEntry.getKey(), tableEntry.getValue()));
            tableCountLimit.validateNumberOfTables(mappedTables.size());
        }
        return mappedTables;
    }

    private List<TableMetadata> mapOneTable(ResultSet columnList, String tableName, String tableComment) throws SQLException {
        switch (seekTable(columnList, tableName)) {
        case END_OF_RESULT_SET:
            // no more columns at all
            return Collections.emptyList();
        case NOT_FOUND:
            // try next table
            logSkippingTableWithEmptyColumns(tableName);
            return Collections.emptyList();
        case FOUND:
            break;
        }
        final List<ColumnMetadata> columns = getColumnReader().mapCurrentTableColumns(columnList);
        if (columns.isEmpty()) {
            logSkippingTableWithEmptyColumns(tableName);
            return Collections.emptyList();
        }

        TableMetadata mappedTable = new TableMetadata(adjustIdentifierCase(tableName), //
                "", // == protected BaseTableMetadataReader.DEFAULT_TABLE_ADAPTER_NOTES,
                columns, tableComment);
        LOGGER.finer(() -> "Read table metadata: " + mappedTable.describe());
        return List.of(mappedTable);
    }

    /**
     * Forward the ResultSet cursor to skip all lexicographically smaller schema names.
     * 
     * @param columnList ResultSet generated by DatabaseMetadata::getColumns()
     * @param schemaName Name of the schema we are looking for
     * @return SkipAheadResult indicating the result of the search
     * @throws SQLException if reading from the ResultSet fails
     */
    private SeekResult seekSchema(ResultSet columnList, String schemaName) throws SQLException {
        if (columnList.isAfterLast()) {
            return SeekResult.END_OF_RESULT_SET;
        }
        while (schemaName.compareTo(readSchemaName(columnList)) > 0) {
            if (!columnList.next()) {
                // end of the rope; no more columns
                return SeekResult.END_OF_RESULT_SET;
            }
        }
        if (schemaName.equals(readSchemaName(columnList))) {
            return SeekResult.FOUND;
        }
        return SeekResult.NOT_FOUND;
    }

    /**
     * Forward the ResultSet cursor to skip all lexicographically smaller table names within the current schema
     * 
     * @param columnList ResultSet generated by DatabaseMetadata::getColumns()
     * @param tableName  Name of the table we are looking for
     * @return SkipAheadResult indicating the result of the search
     * @throws SQLException if reading from the ResultSet fails
     */
    private SeekResult seekTable(ResultSet columnList, String tableName) throws SQLException {
        final String currentSchema = readSchemaName(columnList);
        while (tableName.compareTo(readTableName(columnList)) > 0) {
            if (!columnList.next()) {
                // end of the rope; no more columns
                return SeekResult.END_OF_RESULT_SET;
            }
            if (!currentSchema.equals(readSchemaName(columnList))) {
                return SeekResult.NOT_FOUND;
            }
        }
        if (tableName.equals(readTableName(columnList))) {
            return SeekResult.FOUND;
        }
        return SeekResult.NOT_FOUND;
    }

    /**
     * For the 'mergesort' of table list and column list to work, both must be sorted by the same criteria.
     * Unfortunately, the result of DatabaseMetadata.getTables() is sorted by TABLE_TYPE first, which makes it pretty
     * useless.
     *
     * This method takes all table names (and their comments) and puts them into a tree of sorted maps, so it can be
     * iterated by schema and table name later.
     *
     * // TODO: up for discussion -- it could also be a three-strings data class with comparator methods
     *          put into a single TreeSet
     *
     * @param remoteTables   ResultSet with table metadata
     * @param filteredTables List of acceptable table names; accepts all tables if the list is empty
     * @return The map tree: SchemaName ==> TableName --> TableComment
     * @throws SQLException if access to ResultSet fails
     */
    private SortedMap<String, SortedMap<String, String>> sortTablesResult(ResultSet remoteTables,
            List<String> filteredTables) throws SQLException {
        SortedMap<String, SortedMap<String, String>> sortedSchemas = new TreeMap<>();

        while (remoteTables.next()) {
            final String schemaName = readSchemaName(remoteTables);
            final String tableName = readTableName(remoteTables);
            if (isTableSupported(filteredTables, tableName)) {
                SortedMap<String, String> sortedTables = sortedSchemas.computeIfAbsent(schemaName,
                        (String unused) -> new TreeMap<>());
                final String comment = Optional.ofNullable(readComment(remoteTables)).orElse("");
                sortedTables.put(tableName, comment);
            }
        }

        return sortedSchemas;
    }
}
